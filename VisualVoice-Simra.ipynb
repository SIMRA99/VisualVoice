{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95afeec4",
   "metadata": {},
   "source": [
    "# # AI Tool that creates captions based on the image provided by the user. It is based on MobileNetV2 to predict scenes of the image and use language model such as ChatGPT3 to prompt creative and catchy captions based on the scenes predicted in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd19546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000238186A34C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 710ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "import cv2\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "openai.api_key = \"YOUR  OPENAI API KEY \"\n",
    "\n",
    "# Load the MobileNetV2 model\n",
    "model = MobileNetV2(weights='imagenet')\n",
    "\n",
    "# Create the Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Simra's Image Caption Generator\")\n",
    "window.geometry(\"900x700\")\n",
    "window.configure(bg=\"#FFFACD\")\n",
    "\n",
    "# Declare global variables\n",
    "file_path = \"\"\n",
    "\n",
    "def upload_image():\n",
    "    global file_path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((400, 300))\n",
    "    image = ImageTk.PhotoImage(image)\n",
    "    image_label.configure(image=image)\n",
    "    image_label.image = image\n",
    "    generate_button.configure(state=tk.NORMAL)\n",
    "\n",
    "def recognize_objects_and_scenes(image):\n",
    "    # Preprocess the input image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    # Perform object recognition\n",
    "    predictions = model.predict(np.expand_dims(image, axis=0))\n",
    "    decoded_predictions = decode_predictions(predictions, top=10)[0]\n",
    "\n",
    "    # Perform scene identification\n",
    "    scene_class_name = decode_predictions(predictions, top=1)[0][0][1]\n",
    "\n",
    "    return decoded_predictions, scene_class_name\n",
    "\n",
    "def generate_caption(tone):\n",
    "    global file_path\n",
    "    image = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
    "    _, scene_class_name = recognize_objects_and_scenes(image)\n",
    "\n",
    "    # Generate captions using ChatGPT-3\n",
    "    prompt = f\"The scene in the image is {scene_class_name}. Generate a {tone.lower()} catchy and creative caption .\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        n=3,  # Generate 3 different captions\n",
    "        temperature=0.7,\n",
    "        stop=None,\n",
    "    )\n",
    "    captions = [choice[\"text\"].strip() for choice in response.choices]\n",
    "\n",
    "    display_captions(captions)\n",
    "\n",
    "def display_captions(captions):\n",
    "    caption_label.config(text=\"\\n\".join(captions))\n",
    "\n",
    "# Configure button styles\n",
    "button_style = {\"font\": (\"Arial\", 14), \"bg\": \"#FFC300\", \"fg\": \"#000000\", \"relief\": tk.RAISED, \"width\": 15, \"height\": 1}\n",
    "\n",
    "upload_button = tk.Button(window, text=\"Upload Image\", command=upload_image, **button_style)\n",
    "upload_button.place(relx=0.2, rely=0.1, anchor=tk.CENTER)\n",
    "\n",
    "image_label = tk.Label(window, bg=\"#FFFACD\")\n",
    "image_label.place(relx=0.5, rely=0.3, anchor=tk.CENTER)\n",
    "\n",
    "tone_label = tk.Label(window, text=\"Select Caption Tone:\", font=(\"Arial\", 14), bg=\"#FFFACD\")\n",
    "tone_label.place(relx=0.5, rely=0.5, anchor=tk.CENTER)\n",
    "\n",
    "tone_var = tk.StringVar(window)\n",
    "tone_var.set(\"Adventurous\")  # Default tone\n",
    "tone_dropdown = tk.OptionMenu(window, tone_var, \"Adventurous\", \"Professional\", \"Happy\", \"Sad\", \"Humorous\", \"Motivating\")\n",
    "tone_dropdown.config(font=(\"Arial\", 14), bg=\"#FFC300\", fg=\"#000000\", relief=tk.RAISED, width=15, height=2)\n",
    "tone_dropdown.place(relx=0.5, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "generate_button = tk.Button(window, text=\"Generate Caption\", command=lambda: generate_caption(tone_var.get()), **button_style)\n",
    "generate_button.place(relx=0.5, rely=0.7, anchor=tk.CENTER)\n",
    "generate_button.configure(state=tk.DISABLED)\n",
    "\n",
    "caption_label = tk.Label(window, wraplength=800, font=(\"Arial\", 16), justify=tk.CENTER, bg=\"#FFFACD\")\n",
    "caption_label.place(relx=0.5, rely=0.9, anchor=tk.CENTER)\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7096a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 568ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import openai\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "openai.api_key = \"YOUR  OPENAI API KEY\"\n",
    "\n",
    "# Load the MobileNetV2 model\n",
    "model = MobileNetV2(weights='imagenet')\n",
    "\n",
    "# Create the Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Image Caption Generator\")\n",
    "window.geometry(\"900x700\")\n",
    "window.configure(bg=\"#FFFACD\")\n",
    "\n",
    "# Declare global variables\n",
    "file_path = \"\"\n",
    "\n",
    "def upload_image():\n",
    "    global file_path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((400, 300))\n",
    "    image = ImageTk.PhotoImage(image)\n",
    "    image_label.configure(image=image)\n",
    "    image_label.image = image\n",
    "    generate_button.configure(state=tk.NORMAL)\n",
    "\n",
    "def recognize_objects_and_scenes(image):\n",
    "    # Preprocess the input image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    # Perform object recognition\n",
    "    predictions = model.predict(np.expand_dims(image, axis=0))\n",
    "    decoded_predictions = decode_predictions(predictions, top=1000)[0]\n",
    "\n",
    "    # Perform scene identification\n",
    "    scene_class_name = decode_predictions(predictions, top=1)[0][0][1]\n",
    "\n",
    "    return decoded_predictions, scene_class_name\n",
    "\n",
    "def recognize_text(image):\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    result = reader.readtext(image)\n",
    "    text = ' '.join([res[1] for res in result])\n",
    "    return text\n",
    "\n",
    "def generate_caption(tone):\n",
    "    global file_path\n",
    "    image = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
    "    _, scene_class_name = recognize_objects_and_scenes(image)\n",
    "    recognized_text = recognize_text(image)\n",
    "\n",
    "    # Generate captions using ChatGPT-3\n",
    "    prompt = f\"The scene in the image is {scene_class_name}. The recognized text is '{recognized_text}'. Generate a {tone.lower()} long catchy and creative caption.\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        n=3,  # Generate 3 different captions\n",
    "        temperature=0.7,\n",
    "        stop=None,\n",
    "    )\n",
    "    captions = [choice[\"text\"].strip() for choice in response.choices]\n",
    "\n",
    "    display_captions(captions)\n",
    "\n",
    "def display_captions(captions):\n",
    "    caption_label.config(text=\"\\n\".join(captions))\n",
    "\n",
    "# Configure button styles\n",
    "button_style = {\"font\": (\"Arial\", 14), \"bg\": \"#FFC300\", \"fg\": \"#000000\", \"relief\": tk.RAISED, \"width\": 15, \"height\": 1}\n",
    "\n",
    "upload_button = tk.Button(window, text=\"Upload Image\", command=upload_image, **button_style)\n",
    "upload_button.place(relx=0.2, rely=0.1, anchor=tk.CENTER)\n",
    "\n",
    "image_label = tk.Label(window, bg=\"#FFFACD\")\n",
    "image_label.place(relx=0.5, rely=0.3, anchor=tk.CENTER)\n",
    "\n",
    "tone_label = tk.Label(window, text=\"Select Caption Tone:\", font=(\"Arial\", 14), bg=\"#FFFACD\")\n",
    "tone_label.place(relx=0.5, rely=0.5, anchor=tk.CENTER)\n",
    "\n",
    "tone_var = tk.StringVar(window)\n",
    "tone_var.set(\"Adventurous\")  # Default tone\n",
    "tone_dropdown = tk.OptionMenu(window, tone_var, \"Adventurous\", \"Professional\", \"Happy\", \"Sad\", \"Humorous\", \"Motivating\")\n",
    "tone_dropdown.config(font=(\"Arial\", 14), bg=\"#FFC300\", fg=\"#000000\", relief=tk.RAISED, width=15, height=2)\n",
    "tone_dropdown.place(relx=0.5, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "generate_button = tk.Button(window, text=\"Generate Caption\", command=lambda: generate_caption(tone_var.get()), **button_style)\n",
    "generate_button.place(relx=0.5, rely=0.7, anchor=tk.CENTER)\n",
    "generate_button.configure(state=tk.DISABLED)\n",
    "\n",
    "caption_label = tk.Label(window, wraplength=800, font=(\"Arial\", 16), justify=tk.CENTER, bg=\"#FFFACD\")\n",
    "caption_label.place(relx=0.5, rely=0.9, anchor=tk.CENTER)\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb784c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238ea13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
